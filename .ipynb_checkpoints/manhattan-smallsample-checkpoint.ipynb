{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manhattan OpenStreetMap Data Exploration - P3 Data Analyst\n",
    "\n",
    "### Marie Leaf | February 2016\n",
    "\n",
    "\n",
    "Map Area: [Manhattan, New York, United States](https://www.openstreetmap.org/relation/2552485#map=11/40.7811/-73.9779)  \n",
    "XML OSM Download: [Mapzen Direct](https://s3.amazonaws.com/metro-extracts.mapzen.com/new-york_new-york.osm.bz2)\n",
    "\n",
    "I chose the New York (Manhattan) map because it is the city where I currently live, and am interested in exploring. \n",
    "\n",
    "Manhattan has a population of 1.6 million people (2014) with an influx of commuters on business days that increases the total population to 3.9 million or more than 170,000 people per sq. mile. Manhattan is considered the economic and cultural center of the United States and is home to the United Nations Headquarters and the world's two largest stock exchanges. The city's real estate market consistently ranks amongst the most expensive in the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problems Encountered in the Map\n",
    "\n",
    "After downloading and converting small sample size of the New York City metro area data (1sample.py) and running it against processing 2parse.py, 3explore.py, and 4audit.py files, I noticed some issues with the data: \n",
    "\n",
    "- When auditing the street types, directions came at the end of some street names. I solved this by classifying these directions as street types. \n",
    "- Sometimes the street_type came at the beginning of the string, e.g. Avenue C. I solved this by inlcuding the condition \"and `'Avenue' not in street_name\"` and `\"and 'Road' not in street_name\"` in the `audit_street_type` function\n",
    "- State abbreviations needed to be standardized with capitalization\n",
    "- Some streets were all caps, so added `.lower().title()` on the regex match\n",
    "- There was a lot of zipcode redunancy with the TIGER data so I normalized these keys as zipcode keys, i.e. `tiger:zip_right` and `tiger:zip_left` keys were converted to `zipcode`\n",
    "- Skipped past the GNIS data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Overview\n",
    "\n",
    "This section contains basic statistics about the dataset and the MongoDB queries used to gather them. The data we have here is a snapshot of the lastest version available on Mapzen. And only the last user who contibuted to the all the node’s and way’s are counted.\n",
    "\n",
    "To load json into MongoDB:\n",
    "\n",
    "```> mongoimport -d nanodegree -c manhattan --file sample.osm.json```   \n",
    "```> use nanodegree ```\n",
    "\n",
    "\n",
    "__File Sizes__\n",
    "\n",
    "small_sample.osm : 4.9 MB  \n",
    "small_sample.osm.json : 5.4 MB\n",
    "\n",
    "__Number of documents__\n",
    "\n",
    "```\n",
    "> db.manhattan.find().count()  \n",
    "```\n",
    "Result:\n",
    "```\n",
    "104996\n",
    "```\n",
    "\n",
    "__Number of nodes and ways__\n",
    "\n",
    "```\n",
    "> db.manhattan.aggregate( [ { $group : { \"_id\" : \"$type\", \"count\" : { $sum : 1 } } } ] )\n",
    "```\n",
    "Result:\n",
    "```\n",
    "{ \"_id\" : \"way\", \"count\" : 101849 }\n",
    "{ \"_id\" : \"node\", \"count\" : 3147 } ```\n",
    "\n",
    "__Number of unique users__\n",
    "\n",
    "```\n",
    "> db.manhattan.distinct(\"created.user\").length() \n",
    "```\n",
    "Result:\n",
    "```\n",
    "769```\n",
    "\n",
    "__Top one contributing user__\n",
    "\n",
    "```\n",
    "> db.manhattan.aggregate( [\n",
    "    { $group : {\"_id\" : \"$created.user\", \n",
    "                \"count\" : { \"$sum\" : 1} } },\n",
    "    { $sort : {\"count\" : -1} }, \n",
    "    { $limit : 1 } ] )\n",
    "```\n",
    "Result:\n",
    "```\n",
    "{ \"_id\" : \"woodpeck_fixbot\", \"count\" : 66873 }\n",
    "```\n",
    "\n",
    "__Number of users appearing only once (having one post)__\n",
    "\n",
    "```\n",
    "> db.manhattan.aggregate( [\n",
    "    { $group : {\"_id\" : \"$created.user\", \n",
    "                \"count\" : { \"$sum\" : 1} } },\n",
    "    { $group : {\"_id\" : \"$count\",\n",
    "                \"num_users\": { \"$sum\" : 1} } },\n",
    "    { $sort : {\"_id\" : 1} },\n",
    "    { $limit : 1} ] )\n",
    "```\n",
    "Result:\n",
    "```\n",
    "{ \"_id\" : 1, \"num_users\" : 258 }\n",
    "```\n",
    "\n",
    "__Top unique data sources__\n",
    "``` \n",
    ">    db.manhattan.aggregate( [{\"$match\": {\"source\": {\"$exists\" : 1} } }, \n",
    "    {\"$group\": {\"_id\": \"$source\", \"count\": {\"$sum\":1} } }, \n",
    "    {\"$sort\": {\"count\":-1} },{\"$limit\": 5}])\n",
    "```\n",
    "Result:\n",
    "```\n",
    "{ \"_id\" : \"Yahoo\", \"count\" : 11 }\n",
    "{ \"_id\" : \"county_import_v0.1\", \"count\" : 8 }\n",
    "{ \"_id\" : \"tiger:boundaries\", \"count\" : 7 }\n",
    "{ \"_id\" : \"Microsoft Bing orbital imagery\", \"count\" : 6 }\n",
    "{ \"_id\" : \"yahoo\", \"count\" : 4 }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Additional Ideas and MongoDB Queries\n",
    "\n",
    "\n",
    "__Top 5 Contributers__\n",
    "\n",
    "```\n",
    "> db.manhattan.aggregate( [\n",
    "        { $group : {\"_id\" : \"$created.user\", \n",
    "                \"count\" : { \"$sum\" : 1} } },\n",
    "        { $sort : {\"count\" : -1} }, \n",
    "        { $limit : 1 } ] )```\n",
    "Results:\n",
    "```\n",
    "{ \"_id\" : \"woodpeck_fixbot\", \"count\" : 66873 }\n",
    "{ \"_id\" : \"Rub21_nycbuildings\", \"count\" : 10953 }\n",
    "{ \"_id\" : \"KindredCoda\", \"count\" : 2819 }\n",
    "{ \"_id\" : \"ingalls_nycbuildings\", \"count\" : 2093 }\n",
    "{ \"_id\" : \"dufekin\", \"count\" : 1792 }\n",
    "```\n",
    "\n",
    "\n",
    "__Variability in height (min, max, avg building heights)__  \n",
    "After running 2parse.py, I noticed that 'height' is the second most frequent tag key. \n",
    "\n",
    "```> db.manhattan.aggregate([{'$match': {'height': {'$gt': 0}}}, {'$group': {\n",
    "            '_id': None,\n",
    "            'count': {'$sum': 1},\n",
    "            'min': {'$min': '$height'},\n",
    "            'max': {'$max': '$height'},\n",
    "            'avg': {'$avg': '$height'},\n",
    "            'stdD': {'$stdDevPop': '$height'},\n",
    "            }}, {'$sort': {'height': -1}}]``` \n",
    "\n",
    "            \n",
    "Results:\n",
    "```\n",
    "```\n",
    "\n",
    "__Timestamps__  \n",
    "Buildings, streets, and city in general develops and changes at a rapid pace. After querying the timestamps and seeing that the majority of documents were added in 2009, I suggest that the dataset would benefit from more current data.\n",
    "\n",
    "```> db.manhattan.aggregate([{'$match': {'cuisine': {'$exists': 1}}},\n",
    "                {'$group': {'_id': '$cuisine', 'count': {'$sum': 1}}},\n",
    "                {'$sort': {'count': -1}}, {'$limit': 10}])```\n",
    "Results:\n",
    "```\n",
    "```\n",
    "\n",
    "__Most Common Amenities__\n",
    "\n",
    "```> db.manhattan.aggregate([{'$match': {'amenity': {'$exists': 1}}},\n",
    "                {'$group': {'_id': '$amenity', 'count': {'$sum': 1}}},\n",
    "                {'$sort': {'count': -1}}, {'$limit': 10}]) ```\n",
    "Results:\n",
    "```\n",
    "```\n",
    "\n",
    "__Most Common Cuisines__\n",
    "\n",
    "```> db.manhattan.aggregate( [ \n",
    "    { $match : { \"cuisine\" : { \\$exists : 1} } },\n",
    "    { $group : { \"_id\" : \"\\$cuisine\", \"count\" : { \\$sum : 1} } }, \n",
    "    { $sort : { \"count\" : -1 } },\n",
    "    { $limit : 10} ] )\n",
    "```\n",
    "Results:\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion                        \n",
    "\n",
    "After reviewing the data, I noticed that the bulk of the dataset is outdated...though I believe it has been well cleaned for the purposes of this exercise. It interests me to notice a fair amount of GPS data makes it into OpenStreetMap.org on account of users’ efforts, whether by scripting a map editing bot or otherwise. With a rough GPS data processor in place and working together with a more robust data processor similar to data.pyI think it would be possible to input a great amount of cleaned data to OpenStreetMap.org."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
